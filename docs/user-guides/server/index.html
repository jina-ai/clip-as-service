<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

<meta property="og:title" content="Server API" />
  
<meta property="og:type" content="website" />
  
<meta property="og:url" content="https://clip-as-service.jina.ai/user-guides/server/" />
  
<meta property="og:site_name" content="CLIP-as-service 0.4.13 Documentation" />
  
<meta property="og:description" content="CLIP-as-service is designed in a client-server architecture. A server is a long-running program that receives raw sentences and images from clients, and returns CLIP embeddings to the client. Additionally, clip_server is optimized for speed, low memory footprint and scalability. Horizontal scalin..." />
  
<meta property="og:image" content="https://clip-as-service.jina.ai/_images/server-start.gif" />
  
<meta property="og:image:alt" content="CLIP-as-service 0.4.13 Documentation" />
  
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@JinaAI_">
<meta name="twitter:creator" content="@JinaAI_">
<meta name="description" content="Embed images and sentences into fixed-length vectors via CLIP.">
<meta property="og:description" content="CLIP-as-service is a low-latency high-scalability embedding service for images and texts. It can be easily integrated as a microservice into neural search solutions.">


<script async src="https://www.googletagmanager.com/gtag/js?id=G-E63SXVNDXZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-E63SXVNDXZ');
</script>

<script async defer src="https://buttons.github.io/buttons.js"></script>
    <link rel="index" title="Index" href="../../genindex/" /><link rel="search" title="Search" href="../../search/" /><link rel="next" title="FAQ" href="../faq/" /><link rel="prev" title="Client API" href="../client/" />
        <link rel="canonical" href="https://clip-as-service.jina.ai/user-guides/server.html" />

    <link rel="shortcut icon" href="../../_static/favicon.png"/><meta name="generator" content="sphinx-4.5.0, furo 2022.06.04.1"/>
        <title>Server API - CLIP-as-service 0.4.13 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?digest=40978830699223671f4072448e654b5958f38b89" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    <link rel="stylesheet" type="text/css" href="../../_static/main.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta2/css/all.min.css" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: #4d4d4d;
  --color-brand-primary: #009191;
  --color-brand-content: #009191;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #FBCB67;
  --color-brand-content: #FBCB67;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #FBCB67;
  --color-brand-content: #FBCB67;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
    <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
    <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
    <header class="mobile-header">
        <div class="header-left">
            <label class="nav-overlay-icon" for="__navigation">
                <div class="visually-hidden">Toggle site navigation sidebar</div>
                <i class="icon">
                    <svg>
                        <use href="#svg-menu"></use>
                    </svg>
                </i>
            </label>
        </div>
        <div class="header-center">
            <a href="../../">
                <div class="brand">CLIP-as-service 0.4.13 documentation</div>
            </a>
        </div>
        <div class="header-right">
            <div class="theme-toggle-container theme-toggle-header">
                <button class="theme-toggle">
                    <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
                    <svg class="theme-icon-when-auto">
                        <use href="#svg-sun-half"></use>
                    </svg>
                    <svg class="theme-icon-when-dark">
                        <use href="#svg-moon"></use>
                    </svg>
                    <svg class="theme-icon-when-light">
                        <use href="#svg-sun"></use>
                    </svg>
                </button>
            </div>
            <label class="toc-overlay-icon toc-header-icon" for="__toc">
                <div class="visually-hidden">Toggle table of contents sidebar</div>
                <i class="icon">
                    <svg>
                        <use href="#svg-toc"></use>
                    </svg>
                </i>
            </label>
        </div>
    </header>
    <aside class="sidebar-drawer">
        <div class="sidebar-container">
            
            <div class="sidebar-sticky"><a class="sidebar-brand" href="../../">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../../_static/logo-light.svg" alt="Light Logo" />
    <img class="sidebar-logo only-dark" src="../../_static/logo-dark.svg" alt="Dark Logo" />
  </div>
  
  
</a>
<div class="sd-d-flex-row sd-align-major-spaced">
  <a class="github-button" href="https://github.com/jina-ai/clip-as-service" data-icon="octicon-star" data-show-count="true" aria-label="Star jina-ai/jina on GitHub" style="opacity: 0;">Star</a>
  
</div><form class="sidebar-search-container" method="get" action="../../search/" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
    <p class="caption" role="heading"><span class="caption-text">User Guides</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../client/">Client API</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Server API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Playground</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../playground/embedding/">Text &amp; Image Embedding</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer References</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../api/clip_client/">clip_client package</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api/clip_client.client/">clip_client.client module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/clip_client.helper/">clip_client.helper module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../changelog/">Changelog</a></li>
</ul>

    <p class="caption" role="heading"><span class="caption-text">Ecosystem</span></p>
    <ul>
        <li class="toctree-l1">
            <a class="reference external" href="https://docs.jina.ai">
                <img class="sidebar-ecosys-logo only-light-line" src="../../_static/search-light.svg">
                <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/search-dark.svg">
                Jina</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://hub.jina.ai">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/hub-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/hub-dark.svg">
            Jina Hub</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://finetuner.jina.ai">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/finetuner-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/finetuner-dark.svg">
            Finetuner</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://docarray.jina.ai">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/docarray-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/docarray-dark.svg">
            DocArray</a></li>
        <li class="toctree-l1"><a class="reference internal" href="#">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/cas-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/cas-dark.svg">
            CLIP-as-service</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://github.com/jina-ai/jcloud">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/JCloud-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/JCloud-dark.svg">
            JCloud</a></li>
    </ul>
</div>
</div>

            </div>
            
        </div>
    </aside>
    <div class="main">
        <div class="content">
            <div class="article-container">
                <a href="#" class="back-to-top muted-link">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
                    </svg>
                    <span>Back to top</span>
                </a>
                <div class="content-icon-container"><div class="theme-toggle-container theme-toggle-content">
                        <button class="theme-toggle">
                            <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
                            <svg class="theme-icon-when-auto">
                                <use href="#svg-sun-half"></use>
                            </svg>
                            <svg class="theme-icon-when-dark">
                                <use href="#svg-moon"></use>
                            </svg>
                            <svg class="theme-icon-when-light">
                                <use href="#svg-sun"></use>
                            </svg>
                        </button>
                    </div>
                    <label class="toc-overlay-icon toc-content-icon"
                           for="__toc">
                        <div class="visually-hidden">Toggle table of contents sidebar</div>
                        <i class="icon">
                            <svg>
                                <use href="#svg-toc"></use>
                            </svg>
                        </i>
                    </label>
                </div>
                <article role="main">
                    <section class="tex2jax_ignore mathjax_ignore" id="server-api">
<h1>Server API<a class="headerlink" href="#server-api" title="Permalink to this headline">#</a></h1>
<p>CLIP-as-service is designed in a client-server architecture. A server is a long-running program that receives raw sentences and images from clients, and returns CLIP embeddings to the client. Additionally, <code class="docutils literal notranslate"><span class="pre">clip_server</span></code> is optimized for speed, low memory footprint and scalability.</p>
<ul class="simple">
<li><p>Horizontal scaling: adding more replicas easily with one argument.</p></li>
<li><p>Vertical scaling: using PyTorch JIT, ONNX or TensorRT runtime to speedup single GPU inference.</p></li>
<li><p>Supporting gRPC, HTTP, Websocket protocols with their TLS counterparts, w/o compressions.</p></li>
</ul>
<p>This chapter introduces the API of the server.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>You will need to install server first in Python 3.7+: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">clip-server</span></code>.</p>
</div>
<section id="start-server">
<h2>Start server<a class="headerlink" href="#start-server" title="Permalink to this headline">#</a></h2>
<section id="start-a-pytorch-backed-server">
<h3>Start a PyTorch-backed server<a class="headerlink" href="#start-a-pytorch-backed-server" title="Permalink to this headline">#</a></h3>
<p>Unlike the client, server only has a CLI entrypoint. To start a server, run the following in the terminal:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python -m clip_server
</pre></div>
</div>
<p>Note that it is underscore <code class="docutils literal notranslate"><span class="pre">_</span></code> not the dash <code class="docutils literal notranslate"><span class="pre">-</span></code>.</p>
<p id="server-address">First time running will download the pretrained model (Pytorch <code class="docutils literal notranslate"><span class="pre">ViT-B/32</span></code> by default), load the model, and finally you will get the address information of the server. This information will <a class="reference internal" href="../client/#construct-client"><span class="std std-ref">then be used in clients</span></a>.</p>
<figure class="align-default">
<a class="reference internal image-reference" href="../../_images/server-start.gif"><img alt="../../_images/server-start.gif" src="../../_images/server-start.gif" style="width: 70%;" /></a>
</figure>
</section>
<section id="start-a-onnx-backed-server">
<h3>Start a ONNX-backed server<a class="headerlink" href="#start-a-onnx-backed-server" title="Permalink to this headline">#</a></h3>
<p>To use ONNX runtime for CLIP, you can run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install <span class="s2">&quot;clip_server[onnx]&quot;</span>

python -m clip_server onnx-flow.yml
</pre></div>
</div>
</section>
<section id="start-a-tensorrt-backed-server">
<h3>Start a TensorRT-backed server<a class="headerlink" href="#start-a-tensorrt-backed-server" title="Permalink to this headline">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">nvidia-pyindex</span></code> package needs to be installed first. It allows your <code class="docutils literal notranslate"><span class="pre">pip</span></code> to fetch additional Python modules from the NVIDIA NGC™ PyPI repo:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install nvidia-pyindex
pip install <span class="s2">&quot;clip_server[tensorrt]&quot;</span>

python -m clip_server tensorrt-flow.yml
</pre></div>
</div>
<p>One may wonder where is this <code class="docutils literal notranslate"><span class="pre">onnx-flow.yml</span></code> or <code class="docutils literal notranslate"><span class="pre">tensorrt-flow.yml</span></code> come from. Must be a typo? Believe me, just run it. It should just work. I will explain this YAML file in the next section.</p>
<p>The procedure and UI of ONNX and TensorRT runtime would look the same as Pytorch runtime.</p>
</section>
</section>
<section id="model-support">
<h2>Model support<a class="headerlink" href="#model-support" title="Permalink to this headline">#</a></h2>
<p>Open AI has released 9 models so far. <code class="docutils literal notranslate"><span class="pre">ViT-B/32</span></code> is used as default model in all runtimes. Due to the limitation of some runtime, not every runtime supports all nine models. Please also note that different model give different size of output dimensions. This will affect your downstream applications. For example, switching the model from one to another make your embedding incomparable, which breaks the downstream applications. Here is a list of supported models of each runtime and its corresponding size:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Model</th>
<th>PyTorch</th>
<th>ONNX</th>
<th>TensorRT</th>
<th>Output dimension</th>
</tr>
</thead>
<tbody>
<tr>
<td>RN50</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>1024</td>
</tr>
<tr>
<td>RN101</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>512</td>
</tr>
<tr>
<td>RN50x4</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>640</td>
</tr>
<tr>
<td>RN50x16</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
<td>768</td>
</tr>
<tr>
<td>RN50x64</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
<td>1024</td>
</tr>
<tr>
<td>ViT-B/32</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>512</td>
</tr>
<tr>
<td>ViT-B/16</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>512</td>
</tr>
<tr>
<td>ViT-L/14</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>768</td>
</tr>
<tr>
<td>ViT-L/14-336px</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
<td>768</td>
</tr>
</tbody>
</table>
</section>
<section id="yaml-config">
<h2>YAML config<a class="headerlink" href="#yaml-config" title="Permalink to this headline">#</a></h2>
<p>You may notice that there is a YAML file in our last ONNX example. All configurations are stored in this file. In fact, <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">clip_server</span></code> does <strong>not support</strong> any other argument besides a YAML file. So it is the only source of the truth of your configs.</p>
<p>And to answer your doubt, <code class="docutils literal notranslate"><span class="pre">clip_server</span></code> has three built-in YAML configs as a part of the package resources. When you do <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">clip_server</span></code> it loads the Pytorch config, and when you do <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">clip_server</span> <span class="pre">onnx-flow.yml</span></code> it loads the ONNX config.
In the same way, when you do <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">clip_server</span> <span class="pre">tensorrt-flow.yml</span></code> it loads the TensorRT config.</p>
<p>Let’s look at these three built-in YAML configs:</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--0-input--1" name="tab-set--0" type="radio"><label class="tab-label" for="tab-set--0-input--1">torch-flow.yml</label><div class="tab-content docutils">
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Flow</span><span class="w"></span>
<span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;1&#39;</span><span class="w"></span>
<span class="nt">with</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">51000</span><span class="w"></span>
<span class="nt">executors</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">clip_t</span><span class="w"></span>
<span class="w">    </span><span class="nt">uses</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CLIPEncoder</span><span class="w"></span>
<span class="w">      </span><span class="nt">metas</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">py_modules</span><span class="p">:</span><span class="w"></span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">executors/clip_torch.py</span><span class="w"></span>
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--0-input--2" name="tab-set--0" type="radio"><label class="tab-label" for="tab-set--0-input--2">onnx-flow.yml</label><div class="tab-content docutils">
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Flow</span><span class="w"></span>
<span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;1&#39;</span><span class="w"></span>
<span class="nt">with</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">51000</span><span class="w"></span>
<span class="nt">executors</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">clip_o</span><span class="w"></span>
<span class="w">    </span><span class="nt">uses</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CLIPEncoder</span><span class="w"></span>
<span class="w">      </span><span class="nt">metas</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">py_modules</span><span class="p">:</span><span class="w"></span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">executors/clip_onnx.py</span><span class="w"></span>
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--0-input--3" name="tab-set--0" type="radio"><label class="tab-label" for="tab-set--0-input--3">tensorrt-flow.yml</label><div class="tab-content docutils">
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Flow</span><span class="w"></span>
<span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;1&#39;</span><span class="w"></span>
<span class="nt">with</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">51000</span><span class="w"></span>
<span class="nt">executors</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">clip_r</span><span class="w"></span>
<span class="w">    </span><span class="nt">uses</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CLIPEncoder</span><span class="w"></span>
<span class="w">      </span><span class="nt">metas</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">py_modules</span><span class="p">:</span><span class="w"></span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">executors/clip_tensorrt.py</span><span class="w"></span>
</pre></div>
</div>
</div>
</div>
<p>Basically, each YAML file defines a <a class="reference external" href="https://docs.jina.ai/fundamentals/flow/">Jina Flow</a>. The complete Jina Flow YAML syntax <a class="reference external" href="https://docs.jina.ai/fundamentals/flow/flow-yaml/#configure-flow-meta-information">can be found here</a>. General parameters of the Flow and Executor can be used here as well. But now we only highlight the most important parameters.</p>
<p>Looking at the YAML file again, we can put it into three subsections as below:</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--1-input--1" name="tab-set--1" type="radio"><label class="tab-label" for="tab-set--1-input--1">CLIP model config</label><div class="tab-content docutils">
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Flow</span><span class="w"></span>
<span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;1&#39;</span><span class="w"></span>
<span class="nt">with</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">51000</span><span class="w"></span>
<span class="nt">executors</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">clip_t</span><span class="w"></span>
<span class="w">    </span><span class="nt">uses</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CLIPEncoder</span><span class="w"></span>
<span class="hll"><span class="w">      </span><span class="nt">with</span><span class="p">:</span><span class="w"></span>
</span><span class="w">      </span><span class="nt">metas</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">py_modules</span><span class="p">:</span><span class="w"></span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">executors/clip_torch.py</span><span class="w"></span>
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--1-input--2" name="tab-set--1" type="radio"><label class="tab-label" for="tab-set--1-input--2">Executor config</label><div class="tab-content docutils">
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Flow</span><span class="w"></span>
<span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;1&#39;</span><span class="w"></span>
<span class="nt">with</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">51000</span><span class="w"></span>
<span class="nt">executors</span><span class="p">:</span><span class="w"></span>
<span class="hll"><span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">clip_t</span><span class="w"></span>
</span><span class="w">    </span><span class="nt">uses</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CLIPEncoder</span><span class="w"></span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span><span class="w"> </span>
<span class="w">      </span><span class="nt">metas</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">py_modules</span><span class="p">:</span><span class="w"></span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">executors/clip_torch.py</span><span class="w"></span>
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--1-input--3" name="tab-set--1" type="radio"><label class="tab-label" for="tab-set--1-input--3">Flow config</label><div class="tab-content docutils">
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Flow</span><span class="w"></span>
<span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;1&#39;</span><span class="w"></span>
<span class="hll"><span class="nt">with</span><span class="p">:</span><span class="w"></span>
</span><span class="hll"><span class="w">  </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">51000</span><span class="w"></span>
</span><span class="nt">executors</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">clip_t</span><span class="w"></span>
<span class="w">    </span><span class="nt">uses</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CLIPEncoder</span><span class="w"></span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span><span class="w"> </span>
<span class="w">      </span><span class="nt">metas</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">py_modules</span><span class="p">:</span><span class="w"></span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">executors/clip_torch.py</span><span class="w"></span>
</pre></div>
</div>
</div>
</div>
<section id="clip-model-config">
<h3>CLIP model config<a class="headerlink" href="#clip-model-config" title="Permalink to this headline">#</a></h3>
<p>For all backends, you can set the following parameters via <code class="docutils literal notranslate"><span class="pre">with</span></code>:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>name</code></td>
<td>Model weights, default is <code>ViT-B/32</code>. Support all OpenAI released pretrained models.</td>
</tr>
<tr>
<td><code>num_worker_preprocess</code></td>
<td>The number of CPU workers for image &amp; text prerpocessing, default 4.</td>
</tr>
<tr>
<td><code>minibatch_size</code></td>
<td>The size of a minibatch for CPU preprocessing and GPU encoding, default 64. Reduce the size of it if you encounter OOM on GPU.</td>
</tr>
</tbody>
</table>
<p>There are also runtime-specific parameters listed below:</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--2-input--1" name="tab-set--2" type="radio"><label class="tab-label" for="tab-set--2-input--1">PyTorch</label><div class="tab-content docutils">
<table border="1" class="docutils">
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>device</code></td>
<td><code>cuda</code> or <code>cpu</code>. Default is <code>None</code> means auto-detect.</td>
</tr>
<tr>
<td><code>jit</code></td>
<td>If to enable Torchscript JIT, default is <code>False</code>.</td>
</tr>
</tbody>
</table>
</div>
<input class="tab-input" id="tab-set--2-input--2" name="tab-set--2" type="radio"><label class="tab-label" for="tab-set--2-input--2">ONNX</label><div class="tab-content docutils">
<table border="1" class="docutils">
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>device</code></td>
<td><code>cuda</code> or <code>cpu</code>. Default is <code>None</code> means auto-detect.</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>For example, to turn on JIT and force PyTorch running on CPU, one can do:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Flow</span><span class="w"></span>
<span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;1&#39;</span><span class="w"></span>
<span class="nt">with</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">51000</span><span class="w"></span>
<span class="nt">executors</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">clip_t</span><span class="w"></span>
<span class="w">    </span><span class="nt">uses</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CLIPEncoder</span><span class="w"></span>
<span class="hll"><span class="w">      </span><span class="nt">with</span><span class="p">:</span><span class="w"> </span>
</span><span class="hll"><span class="w">        </span><span class="nt">jit</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span><span class="w"></span>
</span><span class="hll"><span class="w">        </span><span class="nt">device</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cpu</span><span class="w"></span>
</span><span class="w">      </span><span class="nt">metas</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">py_modules</span><span class="p">:</span><span class="w"></span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">executors/clip_torch.py</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="executor-config">
<h3>Executor config<a class="headerlink" href="#executor-config" title="Permalink to this headline">#</a></h3>
<p>The full list of configs for Executor can be found via <code class="docutils literal notranslate"><span class="pre">jina</span> <span class="pre">executor</span> <span class="pre">--help</span></code>. The most important one is probably <code class="docutils literal notranslate"><span class="pre">replicas</span></code>, which <strong>allows you to run multiple CLIP models in parallel</strong> to achieve horizontal scaling.</p>
<p>To scale to 4 CLIP replicas, simply adding <code class="docutils literal notranslate"><span class="pre">replicas:</span> <span class="pre">4</span></code> under <code class="docutils literal notranslate"><span class="pre">uses:</span></code>:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Flow</span><span class="w"></span>
<span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;1&#39;</span><span class="w"></span>
<span class="nt">with</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">51000</span><span class="w"></span>
<span class="nt">executors</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">clip_t</span><span class="w"></span>
<span class="hll"><span class="w">    </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span><span class="w"></span>
</span><span class="w">    </span><span class="nt">uses</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CLIPEncoder</span><span class="w"></span>
<span class="w">      </span><span class="nt">metas</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">py_modules</span><span class="p">:</span><span class="w"></span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">executors/clip_torch.py</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="flow-config">
<span id="id1"></span><h3>Flow config<a class="headerlink" href="#flow-config" title="Permalink to this headline">#</a></h3>
<p>Flow configs are the ones under top-level <code class="docutils literal notranslate"><span class="pre">with:</span></code>. We can see the <code class="docutils literal notranslate"><span class="pre">port:</span> <span class="pre">51000</span></code> is configured there. Besides <code class="docutils literal notranslate"><span class="pre">port</span></code>, there are some common parameters you might need.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>protocol</code></td>
<td>Communication protocol between server and client.  Can be <code>grpc</code>, <code>http</code>, <code>websocket</code>.</td>
</tr>
<tr>
<td><code>cors</code></td>
<td>Only effective when <code>protocol=http</code>. If set, a CORS middleware is added to FastAPI frontend to allow cross-origin access.</td>
</tr>
<tr>
<td><code>prefetch</code></td>
<td>Control the maximum streamed request inside the Flow at any given time, default is <code>None</code>, means no limit. Setting <code>prefetch</code> to a small number helps solving the OOM problem, but may slow down the streaming a bit.</td>
</tr>
</tbody>
</table>
<p>As an example, to set <code class="docutils literal notranslate"><span class="pre">protocol</span></code> and <code class="docutils literal notranslate"><span class="pre">prefetch</span></code>, one can modify the YAML as follows:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Flow</span><span class="w"></span>
<span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;1&#39;</span><span class="w"></span>
<span class="nt">with</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">51000</span><span class="w"></span>
<span class="hll"><span class="w">  </span><span class="nt">protocol</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">websocket</span><span class="w"></span>
</span><span class="hll"><span class="w">  </span><span class="nt">prefetch</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w"></span>
</span><span class="nt">executors</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">clip_t</span><span class="w"></span>
<span class="w">    </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span><span class="w"></span>
<span class="w">    </span><span class="nt">uses</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CLIPEncoder</span><span class="w"></span>
<span class="w">      </span><span class="nt">metas</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">py_modules</span><span class="p">:</span><span class="w"></span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">executors/clip_torch.py</span><span class="w"></span>
</pre></div>
</div>
</section>
</section>
<section id="environment-variables">
<h2>Environment variables<a class="headerlink" href="#environment-variables" title="Permalink to this headline">#</a></h2>
<p>To start a server with more verbose logging,</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">JINA_LOG_LEVEL</span><span class="o">=</span>DEBUG python -m clip_server
</pre></div>
</div>
<figure class="align-default">
<a class="reference internal image-reference" href="../../_images/server-log.gif"><img alt="../../_images/server-log.gif" src="../../_images/server-log.gif" style="width: 70%;" /></a>
</figure>
<p>To run CLIP-server on 3rd GPU,</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">2</span> python -m clip_server
</pre></div>
</div>
<section id="serve-on-multiple-gpus">
<h3>Serve on Multiple GPUs<a class="headerlink" href="#serve-on-multiple-gpus" title="Permalink to this headline">#</a></h3>
<p>If you have multiple GPU devices, you can leverage them via <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES=RR</span></code>. For example, if you have 3 GPUs and your Flow YAML says <code class="docutils literal notranslate"><span class="pre">replicas:</span> <span class="pre">5</span></code>, then</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span>RR python -m clip_server
</pre></div>
</div>
<p>Will assign GPU devices to the following round-robin fashion:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>GPU device</th>
<th>Replica ID</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td>0</td>
<td>3</td>
</tr>
<tr>
<td>1</td>
<td>4</td>
</tr>
</tbody>
</table>
<p>You can also restrict the visible devices in round-robin assigment by <code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES=RR0:2</span></code>, where <code class="docutils literal notranslate"><span class="pre">0:2</span></code> has the same meaning as Python slice. This will create the following assigment:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>GPU device</th>
<th>Replica ID</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>0</td>
<td>2</td>
</tr>
<tr>
<td>1</td>
<td>3</td>
</tr>
<tr>
<td>0</td>
<td>4</td>
</tr>
</tbody>
</table>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>In pratice, we found it is unnecessary to run <code class="docutils literal notranslate"><span class="pre">clip_server</span></code> on multiple GPUs for two reasons:</p>
<ul class="simple">
<li><p>A single replica even with largest <code class="docutils literal notranslate"><span class="pre">ViT-L/14-336px</span></code> takes only 3.5GB VRAM.</p></li>
<li><p>Real network traffic never utilizes GPU in 100%.</p></li>
</ul>
<p>Based on these two points, it makes more sense to have multiple replicas on a single GPU comparing to have multiple replicas on different GPU, which is kind of waste of resources. <code class="docutils literal notranslate"><span class="pre">clip_server</span></code> scales pretty well by interleaving the GPU time with mulitple replicas.</p>
</div>
</section>
</section>
<section id="monitor-with-prometheus-and-grafana">
<h2>Monitor with Prometheus and Grafana<a class="headerlink" href="#monitor-with-prometheus-and-grafana" title="Permalink to this headline">#</a></h2>
<p>To monitor the performance of the service, you can enable the Prometheus metrics in the Flow YAML:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Flow</span><span class="w"></span>
<span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;1&#39;</span><span class="w"></span>
<span class="nt">with</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">51000</span><span class="w"></span>
<span class="hll"><span class="w">  </span><span class="nt">monitoring</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span><span class="w"></span>
</span><span class="hll"><span class="w">  </span><span class="nt">port_monitoring</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">9090</span><span class="w"></span>
</span><span class="nt">executors</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">clip_t</span><span class="w"></span>
<span class="w">    </span><span class="nt">uses</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CLIPEncoder</span><span class="w"></span>
<span class="w">      </span><span class="nt">metas</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">py_modules</span><span class="p">:</span><span class="w"></span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">executors/clip_torch.py</span><span class="w"></span>
<span class="hll"><span class="w">    </span><span class="nt">monitoring</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
</span><span class="hll"><span class="w">    </span><span class="nt">port_monitoring</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">9091</span><span class="w"></span>
</span></pre></div>
</div>
<p>This enables Prometheus metrics on both Gateway and the CLIP Executor.</p>
<p>Running it gives you:</p>
<figure class="align-default">
<a class="reference internal image-reference" href="../../_images/server-start-monitoring.gif"><img alt="../../_images/server-start-monitoring.gif" src="../../_images/server-start-monitoring.gif" style="width: 80%;" /></a>
</figure>
<p>which exposes two additional endpoints:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">http://localhost:9090</span></code>  for the Gateway</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">http://localhost:9091</span></code>  for the CLIP Executor</p></li>
</ul>
<p>To visualize the metrics in Grafana, you can import this <a class="reference external" href="https://clip-as-service.jina.ai/_static/cas-grafana.json">JSON file of an example dashboard</a>. You will get something as follows:</p>
<figure class="align-default">
<a class="reference internal image-reference" href="../../_images/grafana-dashboard.png"><img alt="../../_images/grafana-dashboard.png" src="../../_images/grafana-dashboard.png" style="width: 80%;" /></a>
</figure>
<p>For more information on monitoring a Flow, <a class="reference external" href="https://docs.jina.ai/fundamentals/flow/monitoring-flow/">please read here</a>.</p>
</section>
<section id="serve-with-tls">
<h2>Serve with TLS<a class="headerlink" href="#serve-with-tls" title="Permalink to this headline">#</a></h2>
<p>You can turn on TLS for HTTP and gRPC protocols. Your Flow YAML should be changed to the following:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Flow</span><span class="w"></span>
<span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;1&#39;</span><span class="w"></span>
<span class="nt">with</span><span class="p">:</span><span class="w"></span>
<span class="hll"><span class="w">  </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8443</span><span class="w"></span>
</span><span class="hll"><span class="w">  </span><span class="nt">protocol</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">http</span><span class="w"></span>
</span><span class="w">  </span><span class="nt">cors</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w"></span>
<span class="hll"><span class="w">  </span><span class="nt">uvicorn_kwargs</span><span class="p">:</span><span class="w"></span>
</span><span class="hll"><span class="w">    </span><span class="nt">ssl_keyfile_password</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">blahblah</span><span class="w"></span>
</span><span class="hll"><span class="w">  </span><span class="nt">ssl_certfile</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cert.pem</span><span class="w"></span>
</span><span class="hll"><span class="w">  </span><span class="nt">ssl_keyfile</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">key.pem</span><span class="w"></span>
</span></pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">protocol</span></code> can be either <code class="docutils literal notranslate"><span class="pre">http</span></code> or <code class="docutils literal notranslate"><span class="pre">grpc</span></code>; <code class="docutils literal notranslate"><span class="pre">cert.pem</span></code> or <code class="docutils literal notranslate"><span class="pre">key.pem</span></code> represent both parts of a certificate, key being the private key to the certificate and crt being the signed certificate. You can run the following command in terminal:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>openssl req -newkey rsa:4096 -nodes -sha512 -x509 -days <span class="m">3650</span> -nodes -out cert.pem -keyout key.pem -subj <span class="s2">&quot;/CN=demo-cas.jina.ai&quot;</span>
</pre></div>
</div>
<p>Note that if you are using <code class="docutils literal notranslate"><span class="pre">protocol:</span> <span class="pre">grpc</span></code> then <code class="docutils literal notranslate"><span class="pre">/CN=demo-cas.jina.ai</span></code> must strictly follow the IP address or the domain name of your server. Mismatch IP or domain name would throw an exception.</p>
<p>Certificate and keys can be also generated via <a class="reference external" href="https://letsencrypt.org/">letsencrypt.org</a>, which is a free SSL provider.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Note that note every port support HTTPS. Commonly support ports are: <code class="docutils literal notranslate"><span class="pre">443</span></code>, <code class="docutils literal notranslate"><span class="pre">2053</span></code>, <code class="docutils literal notranslate"><span class="pre">2083</span></code>, <code class="docutils literal notranslate"><span class="pre">2087</span></code>, <code class="docutils literal notranslate"><span class="pre">2096</span></code>, <code class="docutils literal notranslate"><span class="pre">8443</span></code>.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If you are using Cloudflare proxied DNS, please be aware:</p>
<ul class="simple">
<li><p>you need to turn on gRPC support manually, <a class="reference external" href="https://support.cloudflare.com/hc/en-us/articles/360050483011-Understanding-Cloudflare-gRPC-support">please follow the guide here</a>;</p></li>
<li><p>the free tier of Cloudflare has 100s hard limit on the timeout, meaning sending big batch to a CPU server may throw 524 to the client-side.</p></li>
</ul>
</div>
<p>When the server is successfully running, you can connect to it via client by setting <code class="docutils literal notranslate"><span class="pre">server</span></code> to <code class="docutils literal notranslate"><span class="pre">https://</span></code> or <code class="docutils literal notranslate"><span class="pre">grpcs://</span></code> as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">clip_client</span> <span class="kn">import</span> <span class="n">Client</span>

<span class="n">c</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s1">&#39;grpcs://demo-cas.jina.ai:2096&#39;</span><span class="p">)</span>

<span class="n">r</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="s1">&#39;First do it&#39;</span><span class="p">,</span>
        <span class="s1">&#39;then do it right&#39;</span><span class="p">,</span>
        <span class="s1">&#39;then do it better&#39;</span><span class="p">,</span>
        <span class="s1">&#39;https://picsum.photos/200&#39;</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="deploy-on-jcloud">
<h2>Deploy on JCloud<a class="headerlink" href="#deploy-on-jcloud" title="Permalink to this headline">#</a></h2>
<p>You can deploy <code class="docutils literal notranslate"><span class="pre">CLIPTorchEncoder</span></code> on JCloud.
A minimum YAML file <code class="docutils literal notranslate"><span class="pre">flow.yml</span></code> is as follows:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">jtype</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Flow</span><span class="w"></span>
<span class="nt">executors</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CLIPTorchEncoder</span><span class="w"> </span><span class="c1"># The name of the encoder</span><span class="w"></span>
<span class="w">    </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">jinahub+docker://CLIPTorchEncoder</span><span class="w"></span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>All Executors’ <code class="docutils literal notranslate"><span class="pre">uses</span></code> must follow the format <code class="docutils literal notranslate"><span class="pre">jinahub+docker://MyExecutor</span></code> (from <a class="reference external" href="https://hub.jina.ai">Jina Hub</a>) to avoid any local file dependencies.</p>
</div>
<p>To deploy,</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ jc deploy flow.yml
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">jc</span> <span class="pre">deploy</span></code> is the command to deploy a Jina project to JCloud.
Learn more about <a class="reference external" href="https://github.com/jina-ai/jcloud">JCloud usage</a>.</p>
<p>The Flow is successfully deployed when you see:</p>
<figure class="align-default">
<a class="reference internal image-reference" href="../../_images/jc-deploy.png"><img alt="../../_images/jc-deploy.png" src="../../_images/jc-deploy.png" style="width: 60%;" /></a>
</figure>
<p>After deploying on jcloud, you can connect to it via client by setting  <code class="docutils literal notranslate"><span class="pre">grpcs://</span></code> as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">clip_client</span> <span class="kn">import</span> <span class="n">Client</span>

<span class="n">c</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="s1">&#39;grpcs://174eb69ba3.wolf.jina.ai&#39;</span><span class="p">)</span>  <span class="c1"># This is the URL you get from previous step</span>

<span class="n">r</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="s1">&#39;First do it&#39;</span><span class="p">,</span>
        <span class="s1">&#39;then do it right&#39;</span><span class="p">,</span>
        <span class="s1">&#39;then do it better&#39;</span><span class="p">,</span>
        <span class="s1">&#39;https://picsum.photos/200&#39;</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
</pre></div>
</div>
<p>will give you:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[ 0.03480401 -0.23519686  0.01041038 ... -0.5229086  -0.10081214
   -0.08695138]
 [-0.0683605  -0.00324154  0.01490371 ... -0.50309485 -0.06193433
   -0.08574048]
 [ 0.15041807 -0.07933374 -0.06650036 ... -0.46410388 -0.08535041
   0.04270519]
 [-0.16183889  0.10636599 -0.2062868  ... -0.41244072  0.19485454
   0.05658712]]
</pre></div>
</div>
<p>It means the client and the JCloud server are now connected. Well done!</p>
</section>
</section>

                </article>
            </div>
            <footer>
                
                <div class="related-pages">
                    <a class="next-page" href="../faq/">
                        <div class="page-info">
                            <div class="context">
                                <span>Next</span>
                            </div>
                            <div class="title">FAQ</div>
                        </div>
                        <svg>
                            <use href="#svg-arrow-right"></use>
                        </svg>
                    </a>
                    <a class="prev-page" href="../client/">
                        <svg>
                            <use href="#svg-arrow-right"></use>
                        </svg>
                        <div class="page-info">
                            <div class="context">
                                <span>Previous</span>
                            </div>
                            
                            <div class="title">Client API</div>
                            
                        </div>
                    </a>
                </div>
                <div class="bottom-of-page">
                    <div class="left-details">
                        <div class="copyright">
                            Copyright &#169; Jina AI Limited. All rights reserved.
                        </div><div class="last-updated">
                            Last updated on Jun 09, 2022</div>
                    </div>
                    <div class="right-details">
                        <div class="social-btns">
                            <a class='social-btn' href="https://github.com/jina-ai/clip-as-service/" aria-label="GitHub"
                               target="_blank" rel="noreferrer"> <i class="fab fa-github"></i></a>
                            <a class='social-btn' href="https://slack.jina.ai" aria-label="Slack" target="_blank"
                               rel="noreferrer"> <i class="fab fa-slack"></i></a>
                            <a class='social-btn' href="https://youtube.com/c/jina-ai" aria-label="YouTube"
                               target="_blank" rel="noreferrer"> <i class="fab fa-youtube"></i></a>
                            <a class='social-btn' href="https://twitter.com/JinaAI_" aria-label="Twitter"
                               target="_blank" rel="noreferrer"> <i class="fab fa-twitter"></i></a>
                            <a class='social-btn' href="https://www.linkedin.com/company/jinaai/" aria-label="LinkedIn"
                               target="_blank" rel="noreferrer"> <i class="fab fa-linkedin"></i></a>
                        </div>
                    </div>
                </div>
                
            </footer>
        </div>
        <aside class="toc-drawer">
            
            
            <div class="toc-sticky toc-scroll">
                <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
                </div>
                <div class="toc-tree-container">
                    <div class="toc-tree">
                        <ul>
<li><a class="reference internal" href="#">Server API</a><ul>
<li><a class="reference internal" href="#start-server">Start server</a><ul>
<li><a class="reference internal" href="#start-a-pytorch-backed-server">Start a PyTorch-backed server</a></li>
<li><a class="reference internal" href="#start-a-onnx-backed-server">Start a ONNX-backed server</a></li>
<li><a class="reference internal" href="#start-a-tensorrt-backed-server">Start a TensorRT-backed server</a></li>
</ul>
</li>
<li><a class="reference internal" href="#model-support">Model support</a></li>
<li><a class="reference internal" href="#yaml-config">YAML config</a><ul>
<li><a class="reference internal" href="#clip-model-config">CLIP model config</a></li>
<li><a class="reference internal" href="#executor-config">Executor config</a></li>
<li><a class="reference internal" href="#flow-config">Flow config</a></li>
</ul>
</li>
<li><a class="reference internal" href="#environment-variables">Environment variables</a><ul>
<li><a class="reference internal" href="#serve-on-multiple-gpus">Serve on Multiple GPUs</a></li>
</ul>
</li>
<li><a class="reference internal" href="#monitor-with-prometheus-and-grafana">Monitor with Prometheus and Grafana</a></li>
<li><a class="reference internal" href="#serve-with-tls">Serve with TLS</a></li>
<li><a class="reference internal" href="#deploy-on-jcloud">Deploy on JCloud</a></li>
</ul>
</li>
</ul>

                    </div>
                </div>
            </div>
            
            
        </aside>
    </div>
</div>
<img referrerpolicy="no-referrer-when-downgrade"
     src="https://static.scarf.sh/a.png?x-pxid=2823e771-0e1e-4320-8fde-48bc48e53262"/><script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/scripts/furo.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/tabs.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/vue@2/dist/vue.min.js"></script>
    </body>
</html>